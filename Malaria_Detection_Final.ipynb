{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59c8fbc36e71ab5539bd1cc6034cf6886638c35c"},"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport os\nfrom PIL import Image\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import load_img\nfrom keras.utils import np_utils","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a661de01863787c99ada83afa636f8b3a9670f0"},"cell_type":"code","source":"#We create two arrays to contain our infected and non-infected images respectively\nparasitized_data = os.listdir('../input/cell_images/cell_images/Parasitized/')\nprint(parasitized_data[:10]) #the output we get are the .png files\n\nuninfected_data = os.listdir('../input/cell_images/cell_images/Uninfected/')\nprint('\\n')\nprint(uninfected_data[:10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## We will now visualize the data to better understand the difference between infected and non-infected blood cells ##"},{"metadata":{"_uuid":"3c24deb9b2a4feed37e9f5a5814c799ecbd5894d"},"cell_type":"markdown","source":"## Infected Cells ##"},{"metadata":{"trusted":true,"_uuid":"6ba57170ddc6430f931117c37042d41d00e7b5ac"},"cell_type":"code","source":"plt.figure(figsize = (12,12))\nfor i in range(4):\n    plt.subplot(1, 4, i+1)\n    img = cv2.imread('../input/cell_images/cell_images/Parasitized' + \"/\" + parasitized_data[i])\n    plt.imshow(img)\n    plt.title('PARASITIZED : 1')\n    plt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c66b93bf1a700ac0b4c7b8c9dea872ce796f11a4"},"cell_type":"markdown","source":"## Non-infected Cells"},{"metadata":{"trusted":true,"_uuid":"77567eb7e5a644c03498b58bfa38143c1035e211"},"cell_type":"code","source":"plt.figure(figsize = (12,12))\nfor i in range(4):\n    plt.subplot(1, 4, i+1)\n    img = cv2.imread('../input/cell_images/cell_images/Uninfected' + \"/\" + uninfected_data[i+1])\n    plt.imshow(img)\n    plt.title('UNINFECTED : 0')\n    plt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"058cb142b10476e43251c572bc466daefcd8f133"},"cell_type":"markdown","source":"## One can clearly see the difference between the infected and uninfected blood cells. You can also notice that the scale of each image is different and inconsistent ##"},{"metadata":{"trusted":true,"_uuid":"89f4f863573c25855f53a7c5d2b35971789d7e88"},"cell_type":"code","source":"data = []\nlabels = []\nfor img in parasitized_data:\n    try:\n        img_read = plt.imread('../input/cell_images/cell_images/Parasitized/' + \"/\" + img)\n        img_resize = cv2.resize(img_read, (50, 50))\n        img_array = img_to_array(img_resize)\n        data.append(img_array)\n        labels.append(1)\n    except:\n        None\n        \nfor img in uninfected_data:\n    try:\n        img_read = plt.imread('../input/cell_images/cell_images/Uninfected' + \"/\" + img)\n        img_resize = cv2.resize(img_read, (50, 50))\n        img_array = img_to_array(img_resize)\n        data.append(img_array)\n        labels.append(0)\n    except:\n        None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"edb2d2f12c9f683c12f546741ec50f0512a49b5c"},"cell_type":"code","source":"plt.imshow(data[0])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a610fb95dcf4f138e0484348297116429563af89"},"cell_type":"code","source":"image_data = np.array(data)\nlabels = np.array(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e7e836f2f44aac1151fe7ceabac77f9d1795cc9"},"cell_type":"code","source":"idx = np.arange(image_data.shape[0])\nnp.random.shuffle(idx)\nimage_data = image_data[idx]\nlabels = labels[idx]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6951926a19ee22f750e522b71e682e2bedef338"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(image_data, labels, test_size = 0.2, random_state = 101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3bf22f4982ba4f15f2f89307568f09fdcfa852ee"},"cell_type":"code","source":"y_train = np_utils.to_categorical(y_train, num_classes = 2)\ny_test = np_utils.to_categorical(y_test, num_classes = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e9125664ed8cde29e36576928e32900fd200564e"},"cell_type":"code","source":"print(f'SHAPE OF TRAINING IMAGE DATA : {x_train.shape}')\nprint(f'SHAPE OF TESTING IMAGE DATA : {x_test.shape}')\nprint(f'SHAPE OF TRAINING LABELS : {y_train.shape}')\nprint(f'SHAPE OF TESTING LABELS : {y_test.shape}')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c95d884fcef6181a57a0993b5584c83ca7781f49"},"cell_type":"markdown","source":"## Building the CNN Model (Without Data Augmentation)"},{"metadata":{"trusted":true,"_uuid":"866a4e2b75a07372b76a747095795f26707d11ed"},"cell_type":"code","source":"import keras\nfrom keras.layers import Dense, Conv2D\nfrom keras.layers import Flatten\nfrom keras.layers import MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers import Activation\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Dropout\nfrom keras.models import Sequential\nfrom keras import backend as K\n\nfrom keras import optimizers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb05508476add0d472e706a4f2cd475eb63635ec"},"cell_type":"code","source":"def CNNbuild(height, width, classes, channels):\n    model = Sequential()\n    \n    inputShape = (height, width, channels)\n    chanDim = -1\n    \n    if K.image_data_format() == 'channels_first':\n        inputShape = (channels, height, width)\n    model.add(Conv2D(32, (3,3), activation = 'relu', input_shape = inputShape))\n    model.add(MaxPooling2D(2,2))\n    model.add(BatchNormalization(axis = chanDim))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(32, (3,3), activation = 'relu'))\n    model.add(MaxPooling2D(2,2))\n    model.add(BatchNormalization(axis = chanDim))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(32, (3,3), activation = 'relu'))\n    model.add(MaxPooling2D(2,2))\n    model.add(BatchNormalization(axis = chanDim))\n    model.add(Dropout(0.2))\n\n    model.add(Flatten())\n    \n    model.add(Dense(512, activation = 'relu'))\n    model.add(BatchNormalization(axis = chanDim))\n    model.add(Dropout(0.5))\n    model.add(Dense(classes, activation = 'softmax'))\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"365a02adfd89e0e59f3c8c21a4425836002b6203"},"cell_type":"code","source":"#instantiate the model\nheight = 50\nwidth = 50\nclasses = 2\nchannels = 3\nmodel = CNNbuild(height = height, width = width, classes = classes, channels = channels)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7db9b17df502d83187c2e2af9b4259d982296357"},"cell_type":"code","source":"#compile the model\nmodel.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2278ad7d92b65fc850a1217b294500e2d05f2f7d"},"cell_type":"code","source":"#fit the model onto the dataset\nh = model.fit(x_train, y_train, epochs = 20, batch_size = 32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4cd1ac55e2d8f5d0c3d7700b7b9b737de4b5a9b"},"cell_type":"code","source":"plt.figure(figsize = (18,8))\nplt.plot(range(20), h.history['acc'], label = 'Training Accuracy')\nplt.plot(range(20), h.history['loss'], label = 'Taining Loss')\n#ax1.set_xticks(np.arange(0, 31, 5))\nplt.xlabel(\"Number of Epoch's\")\nplt.ylabel('Accuracy/Loss Value')\nplt.title('Training Accuracy and Training Loss')\nplt.legend(loc = \"best\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"baa8a5925ca50faac1c809cd5c8faeba3b143b81"},"cell_type":"code","source":"#evaluate the model on test data\npredictions = model.evaluate(x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc58c1a7f89c8113cfdeb64d8c5d6e9ba9bd0ea0"},"cell_type":"code","source":"print(f'LOSS : {predictions[0]}')\nprint(f'ACCURACY : {predictions[1]}')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"97e629b8a2b231d825af4afabe73f0f658e48a1f"},"cell_type":"markdown","source":"## Implementing Data Augmentation ##"},{"metadata":{"trusted":true,"_uuid":"f161b132cd2f7df5ac6124fe9c1629131fd3a105"},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7325b34eeda560b852ee8ea29b1ed5782df82ea"},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale = 1/255.,\n                                  horizontal_flip = True,\n                                  width_shift_range = 0.2,\n                                  height_shift_range = 0.2,\n                                  fill_mode = 'nearest',\n                                  zoom_range = 0.3,\n                                  rotation_range = 30)\nval_datagen = ImageDataGenerator(rescale = 1/255.)\n\ntrain_generator = train_datagen.flow(x_train, y_train, batch_size = 64, shuffle = False)\nval_generator = val_datagen.flow(x_test, y_test, batch_size = 64, shuffle = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"995c0798092409f4e32b68ea208cbe5a7eece0b5"},"cell_type":"code","source":"#calling the same model as above\nmodel_aug = CNNbuild(height = height, width = width, classes = classes, channels = channels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d74920e2625f07d8975312eac2bf76cc8cc9580"},"cell_type":"code","source":"#compile the model\noptim = optimizers.Adam(lr = 0.001, decay = 0.001 / 64)\nmodel_aug.compile(loss = 'categorical_crossentropy', optimizer = optim, metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4ef1687140dd76da4fab792ff50e73c5099f112"},"cell_type":"code","source":"#fit the model on the augmented dataset\nh_aug = model_aug.fit_generator(train_generator, steps_per_epoch = len(x_train) // 64, epochs = 50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"913388c82ace491f3f2e93dddc38622d0cc01d0c"},"cell_type":"code","source":"#evaluate the model on augmented test data\npredict = model_aug.evaluate_generator(val_generator, steps = 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"266845dd0c00ebe8ebe3b29b822c6c8cffc785cb"},"cell_type":"code","source":"print(f'LOSS ON TEST DATA AFTER DATA AUGMENTATION : {predict[0]}')\nprint(f'ACCURACY ON TEST DATA AFTER DATA AUGMENTATION : {predict[1]}')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d3fc713ce06bbb0748cadc98990f02fbf0778e7f"},"cell_type":"markdown","source":"## As you can see there is a slight improvement on the testing accuracy on the augmented dataset as comapred to dataset without data augmentation\n\n## So data augmentation can prove very useful when the amount of dataset available at hand is very less"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}